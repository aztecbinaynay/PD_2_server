{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\Toshiba\\Documents\\PD2_john\\databases\\data_1687589315209.txt\"\n",
    "\n",
    "result = {}\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "header = lines[0].strip().split(\"\\t\")  # Get the column names from the first line\n",
    "\n",
    "for i in range(len(header)):\n",
    "    column_values = [\n",
    "        float(row.strip().split(\"\\t\")[i]) for row in lines[1:]\n",
    "    ]  # Convert values to floats\n",
    "    result[header[i]] = column_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1810"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[\"AirFlow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\n",
    "    r\"C:\\Users\\Toshiba\\Documents\\PD2_john\\databases\\SensorReadings.db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the SensorReadings table\n",
    "cursor.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS SensorReadings (\n",
    "        ID INTEGER PRIMARY KEY,\n",
    "        UserID INTEGER NOT NULL,\n",
    "        Therm TEXT,\n",
    "        ECG TEXT,\n",
    "        Airflow TEXT,\n",
    "        Snore TEXT,\n",
    "        SpO2 TEXT,\n",
    "        HR TEXT,\n",
    "        TimeIn DATETIME,\n",
    "        TimeOut DATETIME\n",
    "    )\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_time = datetime(2023, 6, 12, 8, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generate a random 6-digit userID using letters and digits\n",
    "userID = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
    "\n",
    "# Define the start time and end time for TimeIn and TimeOut\n",
    "start_time = datetime(2023, 6, 12, 8, 0, 0)\n",
    "end_time = start_time + timedelta(hours=8)\n",
    "\n",
    "# Define the number of data points\n",
    "num_data_points = 691200\n",
    "\n",
    "# Convert lists to strings\n",
    "therm_data = str([random.randint(0, 500) for _ in range(num_data_points)])\n",
    "ecg_data = str([random.randint(0, 500) for _ in range(num_data_points)])\n",
    "airflow_data = str([random.randint(0, 500) for _ in range(num_data_points)])\n",
    "snore_data = str([random.randint(0, 500) for _ in range(num_data_points)])\n",
    "spo2_data = str([random.randint(0, 500) for _ in range(num_data_points)])\n",
    "hr_data = str([random.randint(0, 500) for _ in range(num_data_points)])\n",
    "\n",
    "# Create the dictionary with keys and values\n",
    "data_dict = {\n",
    "    \"UserID\": userID,\n",
    "    \"Therm\": therm_data,\n",
    "    \"ECG\": ecg_data,\n",
    "    \"Airflow\": airflow_data,\n",
    "    \"Snore\": snore_data,\n",
    "    \"SpO2\": spo2_data,\n",
    "    \"HR\": hr_data,\n",
    "    \"TimeIn\": start_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"TimeOut\": end_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-06-12 08:00:00'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[\"TimeIn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert values into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\n",
    "    r\"C:\\Users\\Toshiba\\Documents\\PD2_john\\databases\\SensorReadings.db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insert the data into the table\n",
    "cursor.execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO SensorReadings (UserID, Therm, ECG, Airflow, Snore, SpO2, HR, TimeIn, TimeOut)\n",
    "    VALUES (:UserID, :Therm, :ECG, :Airflow, :Snore, :SpO2, :HR, :TimeIn, :TimeOut)\n",
    "\"\"\",\n",
    "    data_dict,\n",
    ")\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Data Successfully\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\n",
    "    r\"C:\\Users\\Toshiba\\Documents\\PD2_john\\databases\\SensorReadings.db\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "# Function to retrieve a specific row based on UserID\n",
    "def retrieve_row_by_userID(userID):\n",
    "    # Execute the SELECT statement with a WHERE clause\n",
    "    cursor.execute(\"SELECT * FROM SensorReadings WHERE UserID=?\", (userID,))\n",
    "\n",
    "    # Fetch the row from the result\n",
    "    row = cursor.fetchone()\n",
    "\n",
    "    if row is not None:\n",
    "        # Extract the values from the row\n",
    "        id_, userID, Therm, ECG, Airflow, Snore, SpO2, HR, TimeIn, TimeOut = row\n",
    "\n",
    "        # Create a dictionary to store the retrieved data\n",
    "        data_dict2 = {\n",
    "            \"UserID\": userID,\n",
    "            \"Therm\": Therm,\n",
    "            \"ECG\": ECG,\n",
    "            \"Airflow\": Airflow,\n",
    "            \"Snore\": Snore,\n",
    "            \"SpO2\": SpO2,\n",
    "            \"HR\": HR,\n",
    "            \"TimeIn\": TimeIn,\n",
    "            \"TimeOut\": TimeOut,\n",
    "        }\n",
    "\n",
    "        return data_dict2\n",
    "\n",
    "    else:\n",
    "        return \"row data does not exist\"\n",
    "\n",
    "\n",
    "# Retrieve a specific row based on the provided UserID\n",
    "input_userID = \"OYKKRb\"\n",
    "retrieved_data = retrieve_row_by_userID(input_userID)\n",
    "\n",
    "# Process the retrieved data\n",
    "if retrieved_data is not None:\n",
    "    print(\"Retrieved Data Successfully\")\n",
    "else:\n",
    "    print(\"No data found for the provided UserID.\")\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn Sensor Data from Str to Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "therm_data = ast.literal_eval(retrieved_data[\"Therm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 691200)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(therm_data), len(therm_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending to the Backend to save something in the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a post request and see if it will go through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK Data received and processed\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/data\"  # Replace with your backend URL\n",
    "\n",
    "data = {\"color\": \"red\"}  # Replace with your data\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print(response.status_code, response.reason, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send Data to the database using expected sensor readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_2 = data_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACC123'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict_2[\"UserID\"] = \"ACC123\"\n",
    "data_dict_2[\"UserID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:5000/insert\"  # Replace with your backend URL\n",
    "\n",
    "data = data_dict_2  # Replace with your data\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "print(response.status_code, response.reason, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (JOSHUA) Retrieve data from using backend\n",
    "\n",
    "* the following retreival process has been editted to allow the following scenerios:\n",
    "    * see the UserID and all the readings associated with userID. each readings will be differentiated by the difference in time in and time out values\n",
    "    * allow the user to choose which recording is to be taken (one at a time)\n",
    "    \n",
    "* Future updates\n",
    "    * allow the user to retreive all the data associated with a certain UserID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n",
      "{'Time': [{'TimeIn': '2023-06-20 08:00:00', 'TimeOut': '2023-06-20 16:00:00'}], 'UserID': 'Beb123'}\n"
     ]
    }
   ],
   "source": [
    "url = \"http://192.168.1.103:5000/retrieveUserData\"  # endpoint to retreive all the specific records of a certain user\n",
    "data = {\"UserID\": \"Beb123\"}  # Replace with your data\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data_dict2 = response.json()\n",
    "    print(response.status_code, response.reason)\n",
    "    print(data_dict2)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.reason, response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code above retreives all the timeins and timeouts associated with a single user. Also works if user does not exist but you will get an error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "url = \"http://192.168.1.103:5000/retrieveUserInstance\"  # endpoint to retreive all the specific records of a certain user\n",
    "data3 = {\n",
    "    \"UserID\": \"Beb123\",\n",
    "    \"TimeIn\": \"2023-06-20 08:00:00\",\n",
    "    \"TimeOut\": \"2023-06-20 16:00:00\",\n",
    "}  # Replace with your data after retreive the data associated with the user\n",
    "\n",
    "response3 = requests.post(url, json=data3)\n",
    "\n",
    "if response3.status_code == 200:\n",
    "    data_dict3 = response3.json()\n",
    "    print(response3.status_code, response3.reason)\n",
    "else:\n",
    "    print(\"Error:\", response3.status_code, response3.reason, response3.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AHI', 'Airflow', 'Apnea', 'ECG', 'HR', 'Hypopnea', 'Normal', 'Severity', 'Snore', 'SpO2', 'Therm', 'TimeIn', 'TimeOut', 'UserID'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict3.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-06-20 08:00:00'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_dict3[\"TimeIn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[-2.35, -2.35, -2.35, -2.35, -2.35, -2.35, -2.35, -2.35, -2.35, -2.35, -2.35, -2.35, -2.35, -2.35, -'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict3[\"Therm\"][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_dict3.keys():\n",
    "    if i not in [\n",
    "        \"UserID\",\n",
    "        \"TimeIn\",\n",
    "        \"TimeOut\",\n",
    "        \"AHI\",\n",
    "        \"Apnea\",\n",
    "        \"Hypopnea\",\n",
    "        \"Normal\",\n",
    "        \"Severity\",\n",
    "    ]:\n",
    "        data_dict3[i] = ast.literal_eval(data_dict3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHI <class 'int'>\n",
      "Airflow <class 'list'>\n",
      "Apnea <class 'int'>\n",
      "ECG <class 'list'>\n",
      "HR <class 'list'>\n",
      "Hypopnea <class 'int'>\n",
      "Normal <class 'int'>\n",
      "Severity <class 'str'>\n",
      "Snore <class 'list'>\n",
      "SpO2 <class 'list'>\n",
      "Therm <class 'list'>\n",
      "TimeIn <class 'str'>\n",
      "TimeOut <class 'str'>\n",
      "UserID <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for i in data_dict3.keys():\n",
    "    print(i, type(data_dict3[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to get data from the sqlite and make prediction\n",
    "* take data from database\n",
    "* turn data into data to be accepted with minirocket\n",
    "    * turn data into pandas series and create csv out of them\n",
    "    * upsample the data into 34 hz per second\n",
    "* use MiniRocket \n",
    "* Use the SVC pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.interpolate import interp1d\n",
    "import numba\n",
    "import pickle\n",
    "import sktime\n",
    "import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n"
     ]
    }
   ],
   "source": [
    "url = \"http://localhost:5000/retrieve\"  # Replace with your backend URL\n",
    "\n",
    "data = {\"UserID\": \"OYKKRb\"}  # Replace with your data\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data_dict2 = response.json()\n",
    "    print(response.status_code, response.reason)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code, response.reason, response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AHI_table = {\n",
    "    \"Severity\": None,\n",
    "    \"AHI\": None,\n",
    "    \"TimeIn\": data_dict2[\"TimeIn\"],\n",
    "    \"TimeOut\": data_dict2[\"TimeOut\"],\n",
    "    \"UserID\": data_dict2[\"UserID\"],\n",
    "    \"Normal\": 0,\n",
    "    \"Apnea\": 0,\n",
    "    \"Hypopnea\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_dict2.keys():\n",
    "    if i not in [\"UserID\", \"TimeIn\", \"TimeOut\"]:\n",
    "        data_dict2[i] = ast.literal_eval(data_dict2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airflow <class 'list'>\n",
      "ECG <class 'list'>\n",
      "HR <class 'list'>\n",
      "Snore <class 'list'>\n",
      "SpO2 <class 'list'>\n",
      "Therm <class 'list'>\n",
      "TimeIn <class 'str'>\n",
      "TimeOut <class 'str'>\n",
      "UserID <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for i in data_dict2.keys():\n",
    "    print(i, type(data_dict2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_signals_dict(signals_list):\n",
    "    all_df = []\n",
    "    for i in range(len(signals_list)):\n",
    "        signals = signals_list[i]\n",
    "        pd_dict = {}\n",
    "        signals_keys = list(signals.keys())\n",
    "        epochs = int(len(signals[list(signals.keys())[0]]) / 24 / 30)\n",
    "        for i in range(len(signals_keys)):\n",
    "            pd_list = []\n",
    "            curr_col = signals_keys[i]\n",
    "            samples = int(len(signals[curr_col]) / epochs)\n",
    "            for i in range(0, epochs):\n",
    "                pd_list.append(\n",
    "                    pd.Series(signals[curr_col][samples * i : samples * i + samples])\n",
    "                )\n",
    "            pd_dict[curr_col] = pd_list\n",
    "\n",
    "        pd_dict = pd.DataFrame(pd_dict)\n",
    "        # for i in range(pd_dict.columns.size):\n",
    "        #   curr_col = pd_dict.columns[i]\n",
    "        #   for x in pd_dict.index:\n",
    "        #     pd_dict[curr_col][x]= pd_dict[curr_col][x].mean()\n",
    "        all_df.append(pd_dict)\n",
    "\n",
    "    final_df = pd.concat(all_df, ignore_index=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Airflow', 'ECG', 'HR', 'Snore', 'SpO2', 'Therm'])\n"
     ]
    }
   ],
   "source": [
    "# create another dictionary to copy data_dict2 but not include UserID, TimeIn, TimeOut\n",
    "\n",
    "excluded_columns = [\"UserID\", \"TimeOut\", \"TimeIn\"]  # Columns to exclude from the copy\n",
    "\n",
    "new_dict = {\n",
    "    key: value for key, value in data_dict2.items() if key not in excluded_columns\n",
    "}\n",
    "\n",
    "print(new_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs = get_df_from_signals_dict([new_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airflow</th>\n",
       "      <th>ECG</th>\n",
       "      <th>HR</th>\n",
       "      <th>Snore</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>Therm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0      106\n",
       "1      196\n",
       "2       50\n",
       "3      375\n",
       "4 ...</td>\n",
       "      <td>0      241\n",
       "1      317\n",
       "2       11\n",
       "3      280\n",
       "4 ...</td>\n",
       "      <td>0      159\n",
       "1      381\n",
       "2      436\n",
       "3      365\n",
       "4 ...</td>\n",
       "      <td>0      353\n",
       "1      392\n",
       "2      393\n",
       "3      497\n",
       "4 ...</td>\n",
       "      <td>0      299\n",
       "1      134\n",
       "2       98\n",
       "3      327\n",
       "4 ...</td>\n",
       "      <td>0      224\n",
       "1      127\n",
       "2      426\n",
       "3      166\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0      369\n",
       "1       78\n",
       "2      248\n",
       "3      177\n",
       "4 ...</td>\n",
       "      <td>0      436\n",
       "1      235\n",
       "2      493\n",
       "3       21\n",
       "4 ...</td>\n",
       "      <td>0      454\n",
       "1        7\n",
       "2       62\n",
       "3      260\n",
       "4 ...</td>\n",
       "      <td>0      425\n",
       "1      142\n",
       "2      240\n",
       "3      402\n",
       "4 ...</td>\n",
       "      <td>0      422\n",
       "1       62\n",
       "2       33\n",
       "3      314\n",
       "4 ...</td>\n",
       "      <td>0      349\n",
       "1      434\n",
       "2      351\n",
       "3      145\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0      202\n",
       "1      217\n",
       "2      266\n",
       "3      158\n",
       "4 ...</td>\n",
       "      <td>0      437\n",
       "1      193\n",
       "2      173\n",
       "3       34\n",
       "4 ...</td>\n",
       "      <td>0      367\n",
       "1      399\n",
       "2      165\n",
       "3      404\n",
       "4 ...</td>\n",
       "      <td>0      186\n",
       "1       45\n",
       "2      244\n",
       "3       23\n",
       "4 ...</td>\n",
       "      <td>0      191\n",
       "1      410\n",
       "2      188\n",
       "3       28\n",
       "4 ...</td>\n",
       "      <td>0      443\n",
       "1      207\n",
       "2      439\n",
       "3      321\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0      247\n",
       "1      256\n",
       "2      125\n",
       "3      237\n",
       "4 ...</td>\n",
       "      <td>0      254\n",
       "1      289\n",
       "2      353\n",
       "3      320\n",
       "4 ...</td>\n",
       "      <td>0      493\n",
       "1      411\n",
       "2       14\n",
       "3      267\n",
       "4 ...</td>\n",
       "      <td>0      208\n",
       "1      396\n",
       "2      226\n",
       "3       93\n",
       "4 ...</td>\n",
       "      <td>0       51\n",
       "1      454\n",
       "2      190\n",
       "3      253\n",
       "4 ...</td>\n",
       "      <td>0      107\n",
       "1       83\n",
       "2       78\n",
       "3       78\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0      380\n",
       "1      446\n",
       "2      197\n",
       "3      457\n",
       "4 ...</td>\n",
       "      <td>0       88\n",
       "1      197\n",
       "2      318\n",
       "3       34\n",
       "4 ...</td>\n",
       "      <td>0      334\n",
       "1        8\n",
       "2      355\n",
       "3      311\n",
       "4 ...</td>\n",
       "      <td>0      343\n",
       "1      437\n",
       "2       85\n",
       "3      485\n",
       "4 ...</td>\n",
       "      <td>0      446\n",
       "1      237\n",
       "2      388\n",
       "3      114\n",
       "4 ...</td>\n",
       "      <td>0      308\n",
       "1       65\n",
       "2       76\n",
       "3      345\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0      174\n",
       "1      427\n",
       "2      154\n",
       "3      380\n",
       "4 ...</td>\n",
       "      <td>0      296\n",
       "1      166\n",
       "2      350\n",
       "3      188\n",
       "4 ...</td>\n",
       "      <td>0      497\n",
       "1       68\n",
       "2      373\n",
       "3      180\n",
       "4 ...</td>\n",
       "      <td>0      196\n",
       "1      361\n",
       "2      178\n",
       "3      291\n",
       "4 ...</td>\n",
       "      <td>0      259\n",
       "1       37\n",
       "2       41\n",
       "3      446\n",
       "4 ...</td>\n",
       "      <td>0      473\n",
       "1      196\n",
       "2      236\n",
       "3      286\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0      372\n",
       "1      456\n",
       "2      180\n",
       "3      428\n",
       "4 ...</td>\n",
       "      <td>0       97\n",
       "1      367\n",
       "2      459\n",
       "3       39\n",
       "4 ...</td>\n",
       "      <td>0      191\n",
       "1      259\n",
       "2      421\n",
       "3      312\n",
       "4 ...</td>\n",
       "      <td>0       80\n",
       "1      250\n",
       "2      451\n",
       "3      231\n",
       "4 ...</td>\n",
       "      <td>0      447\n",
       "1       58\n",
       "2      415\n",
       "3      211\n",
       "4 ...</td>\n",
       "      <td>0       19\n",
       "1      296\n",
       "2      366\n",
       "3      154\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0       81\n",
       "1      158\n",
       "2      494\n",
       "3      498\n",
       "4 ...</td>\n",
       "      <td>0      262\n",
       "1       16\n",
       "2       91\n",
       "3      497\n",
       "4 ...</td>\n",
       "      <td>0      333\n",
       "1      187\n",
       "2      151\n",
       "3       23\n",
       "4 ...</td>\n",
       "      <td>0      383\n",
       "1      289\n",
       "2      121\n",
       "3      499\n",
       "4 ...</td>\n",
       "      <td>0      500\n",
       "1      487\n",
       "2      356\n",
       "3      131\n",
       "4 ...</td>\n",
       "      <td>0      268\n",
       "1        0\n",
       "2      379\n",
       "3      258\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0      131\n",
       "1      371\n",
       "2      253\n",
       "3      248\n",
       "4 ...</td>\n",
       "      <td>0      363\n",
       "1       33\n",
       "2      240\n",
       "3      248\n",
       "4 ...</td>\n",
       "      <td>0      399\n",
       "1       85\n",
       "2       74\n",
       "3      451\n",
       "4 ...</td>\n",
       "      <td>0       56\n",
       "1      408\n",
       "2      450\n",
       "3      169\n",
       "4 ...</td>\n",
       "      <td>0      410\n",
       "1      441\n",
       "2       39\n",
       "3       94\n",
       "4 ...</td>\n",
       "      <td>0      357\n",
       "1       56\n",
       "2      167\n",
       "3      196\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>0      173\n",
       "1      261\n",
       "2      450\n",
       "3      410\n",
       "4 ...</td>\n",
       "      <td>0       13\n",
       "1      425\n",
       "2      302\n",
       "3      262\n",
       "4 ...</td>\n",
       "      <td>0      170\n",
       "1      499\n",
       "2      448\n",
       "3      243\n",
       "4 ...</td>\n",
       "      <td>0      468\n",
       "1      344\n",
       "2      476\n",
       "3       33\n",
       "4 ...</td>\n",
       "      <td>0       94\n",
       "1      419\n",
       "2       47\n",
       "3      487\n",
       "4 ...</td>\n",
       "      <td>0      239\n",
       "1       45\n",
       "2      277\n",
       "3      181\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Airflow  \\\n",
       "0    0      106\n",
       "1      196\n",
       "2       50\n",
       "3      375\n",
       "4 ...   \n",
       "1    0      369\n",
       "1       78\n",
       "2      248\n",
       "3      177\n",
       "4 ...   \n",
       "2    0      202\n",
       "1      217\n",
       "2      266\n",
       "3      158\n",
       "4 ...   \n",
       "3    0      247\n",
       "1      256\n",
       "2      125\n",
       "3      237\n",
       "4 ...   \n",
       "4    0      380\n",
       "1      446\n",
       "2      197\n",
       "3      457\n",
       "4 ...   \n",
       "..                                                 ...   \n",
       "955  0      174\n",
       "1      427\n",
       "2      154\n",
       "3      380\n",
       "4 ...   \n",
       "956  0      372\n",
       "1      456\n",
       "2      180\n",
       "3      428\n",
       "4 ...   \n",
       "957  0       81\n",
       "1      158\n",
       "2      494\n",
       "3      498\n",
       "4 ...   \n",
       "958  0      131\n",
       "1      371\n",
       "2      253\n",
       "3      248\n",
       "4 ...   \n",
       "959  0      173\n",
       "1      261\n",
       "2      450\n",
       "3      410\n",
       "4 ...   \n",
       "\n",
       "                                                   ECG  \\\n",
       "0    0      241\n",
       "1      317\n",
       "2       11\n",
       "3      280\n",
       "4 ...   \n",
       "1    0      436\n",
       "1      235\n",
       "2      493\n",
       "3       21\n",
       "4 ...   \n",
       "2    0      437\n",
       "1      193\n",
       "2      173\n",
       "3       34\n",
       "4 ...   \n",
       "3    0      254\n",
       "1      289\n",
       "2      353\n",
       "3      320\n",
       "4 ...   \n",
       "4    0       88\n",
       "1      197\n",
       "2      318\n",
       "3       34\n",
       "4 ...   \n",
       "..                                                 ...   \n",
       "955  0      296\n",
       "1      166\n",
       "2      350\n",
       "3      188\n",
       "4 ...   \n",
       "956  0       97\n",
       "1      367\n",
       "2      459\n",
       "3       39\n",
       "4 ...   \n",
       "957  0      262\n",
       "1       16\n",
       "2       91\n",
       "3      497\n",
       "4 ...   \n",
       "958  0      363\n",
       "1       33\n",
       "2      240\n",
       "3      248\n",
       "4 ...   \n",
       "959  0       13\n",
       "1      425\n",
       "2      302\n",
       "3      262\n",
       "4 ...   \n",
       "\n",
       "                                                    HR  \\\n",
       "0    0      159\n",
       "1      381\n",
       "2      436\n",
       "3      365\n",
       "4 ...   \n",
       "1    0      454\n",
       "1        7\n",
       "2       62\n",
       "3      260\n",
       "4 ...   \n",
       "2    0      367\n",
       "1      399\n",
       "2      165\n",
       "3      404\n",
       "4 ...   \n",
       "3    0      493\n",
       "1      411\n",
       "2       14\n",
       "3      267\n",
       "4 ...   \n",
       "4    0      334\n",
       "1        8\n",
       "2      355\n",
       "3      311\n",
       "4 ...   \n",
       "..                                                 ...   \n",
       "955  0      497\n",
       "1       68\n",
       "2      373\n",
       "3      180\n",
       "4 ...   \n",
       "956  0      191\n",
       "1      259\n",
       "2      421\n",
       "3      312\n",
       "4 ...   \n",
       "957  0      333\n",
       "1      187\n",
       "2      151\n",
       "3       23\n",
       "4 ...   \n",
       "958  0      399\n",
       "1       85\n",
       "2       74\n",
       "3      451\n",
       "4 ...   \n",
       "959  0      170\n",
       "1      499\n",
       "2      448\n",
       "3      243\n",
       "4 ...   \n",
       "\n",
       "                                                 Snore  \\\n",
       "0    0      353\n",
       "1      392\n",
       "2      393\n",
       "3      497\n",
       "4 ...   \n",
       "1    0      425\n",
       "1      142\n",
       "2      240\n",
       "3      402\n",
       "4 ...   \n",
       "2    0      186\n",
       "1       45\n",
       "2      244\n",
       "3       23\n",
       "4 ...   \n",
       "3    0      208\n",
       "1      396\n",
       "2      226\n",
       "3       93\n",
       "4 ...   \n",
       "4    0      343\n",
       "1      437\n",
       "2       85\n",
       "3      485\n",
       "4 ...   \n",
       "..                                                 ...   \n",
       "955  0      196\n",
       "1      361\n",
       "2      178\n",
       "3      291\n",
       "4 ...   \n",
       "956  0       80\n",
       "1      250\n",
       "2      451\n",
       "3      231\n",
       "4 ...   \n",
       "957  0      383\n",
       "1      289\n",
       "2      121\n",
       "3      499\n",
       "4 ...   \n",
       "958  0       56\n",
       "1      408\n",
       "2      450\n",
       "3      169\n",
       "4 ...   \n",
       "959  0      468\n",
       "1      344\n",
       "2      476\n",
       "3       33\n",
       "4 ...   \n",
       "\n",
       "                                                  SpO2  \\\n",
       "0    0      299\n",
       "1      134\n",
       "2       98\n",
       "3      327\n",
       "4 ...   \n",
       "1    0      422\n",
       "1       62\n",
       "2       33\n",
       "3      314\n",
       "4 ...   \n",
       "2    0      191\n",
       "1      410\n",
       "2      188\n",
       "3       28\n",
       "4 ...   \n",
       "3    0       51\n",
       "1      454\n",
       "2      190\n",
       "3      253\n",
       "4 ...   \n",
       "4    0      446\n",
       "1      237\n",
       "2      388\n",
       "3      114\n",
       "4 ...   \n",
       "..                                                 ...   \n",
       "955  0      259\n",
       "1       37\n",
       "2       41\n",
       "3      446\n",
       "4 ...   \n",
       "956  0      447\n",
       "1       58\n",
       "2      415\n",
       "3      211\n",
       "4 ...   \n",
       "957  0      500\n",
       "1      487\n",
       "2      356\n",
       "3      131\n",
       "4 ...   \n",
       "958  0      410\n",
       "1      441\n",
       "2       39\n",
       "3       94\n",
       "4 ...   \n",
       "959  0       94\n",
       "1      419\n",
       "2       47\n",
       "3      487\n",
       "4 ...   \n",
       "\n",
       "                                                 Therm  \n",
       "0    0      224\n",
       "1      127\n",
       "2      426\n",
       "3      166\n",
       "4 ...  \n",
       "1    0      349\n",
       "1      434\n",
       "2      351\n",
       "3      145\n",
       "4 ...  \n",
       "2    0      443\n",
       "1      207\n",
       "2      439\n",
       "3      321\n",
       "4 ...  \n",
       "3    0      107\n",
       "1       83\n",
       "2       78\n",
       "3       78\n",
       "4 ...  \n",
       "4    0      308\n",
       "1       65\n",
       "2       76\n",
       "3      345\n",
       "4 ...  \n",
       "..                                                 ...  \n",
       "955  0      473\n",
       "1      196\n",
       "2      236\n",
       "3      286\n",
       "4 ...  \n",
       "956  0       19\n",
       "1      296\n",
       "2      366\n",
       "3      154\n",
       "4 ...  \n",
       "957  0      268\n",
       "1        0\n",
       "2      379\n",
       "3      258\n",
       "4 ...  \n",
       "958  0      357\n",
       "1       56\n",
       "2      167\n",
       "3      196\n",
       "4 ...  \n",
       "959  0      239\n",
       "1       45\n",
       "2      277\n",
       "3      181\n",
       "4 ...  \n",
       "\n",
       "[960 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Airflow': [24.0], 'ECG': [24.0], 'HR': [24.0], 'Snore': [24.0], 'SpO2': [24.0], 'Therm': [24.0]}\n"
     ]
    }
   ],
   "source": [
    "signals_and_sample_rates = {}\n",
    "for i in df_inputs.columns[:]:\n",
    "    signals_and_sample_rates[i] = []\n",
    "    for x in range(len(df_inputs)):\n",
    "        if len(df_inputs.loc[x, i]) / 30 not in signals_and_sample_rates[i]:\n",
    "            signals_and_sample_rates[i].append(len(df_inputs.loc[x, i]) / 30)\n",
    "print(signals_and_sample_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix their sample rates to have 34 samples per second\n",
    "# FUNCTION FOR UPSAMPLING USING CUBIC SPLINE INTERPOLATION\n",
    "def cubic_spline_interpolation(data):\n",
    "    # Define the original 300 data point signal\n",
    "    l = len(data)\n",
    "    x = np.linspace(0, 30, l)\n",
    "    y = data.values\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    y_norm = scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Define the new time points for upsampling\n",
    "    x_new = np.linspace(0, 30, 1020)\n",
    "\n",
    "    # Upsample using cubic spline interpolation\n",
    "    f_cubic = interp1d(x, y_norm, kind=\"cubic\")\n",
    "    y_cubic = f_cubic(x_new)\n",
    "\n",
    "    # Denormalize the data\n",
    "    y_rescaled = scaler.inverse_transform(y_cubic.reshape(-1, 1)).flatten()\n",
    "    y_rescaled_series = pd.Series(y_rescaled)\n",
    "    return y_rescaled_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp1 = df_inputs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe with the same shape as the original dataframe\n",
    "new_df = pd.DataFrame(index=df_temp1.index, columns=df_temp1.columns)\n",
    "\n",
    "# iterate over each cell in the dataframe\n",
    "for i in range(df_temp1.shape[0]):\n",
    "    for j in range(df_temp1.shape[1]):\n",
    "        cell_value = df_temp1.iloc[i, j]\n",
    "        # check if the cell needs to be upsampled/downsampled\n",
    "        if isinstance(cell_value, pd.Series) and len(cell_value) != 1020:\n",
    "            # apply the cubic_spline_interpolation function to the cell value\n",
    "            new_series = cubic_spline_interpolation(cell_value)\n",
    "            # fill the new dataframe with the upsampled/downsampled values\n",
    "            new_df.iloc[i, j] = new_series\n",
    "        else:\n",
    "            # if the cell doesn't need to be upsampled/downsampled, fill the new dataframe with the original value\n",
    "            new_df.iloc[i, j] = cell_value\n",
    "\n",
    "# replace the old dataframe with the new one\n",
    "df_temp1 = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Airflow': [34.0], 'ECG': [34.0], 'HR': [34.0], 'Snore': [34.0], 'SpO2': [34.0], 'Therm': [34.0]}\n"
     ]
    }
   ],
   "source": [
    "signals_and_sample_rates = {}\n",
    "for i in df_temp1.columns[:]:\n",
    "    signals_and_sample_rates[i] = []\n",
    "    for x in range(len(df_temp1)):\n",
    "        if len(df_temp1.loc[x, i]) / 30 not in signals_and_sample_rates[i]:\n",
    "            signals_and_sample_rates[i].append(len(df_temp1.loc[x, i]) / 30)\n",
    "print(signals_and_sample_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airflow</th>\n",
       "      <th>ECG</th>\n",
       "      <th>HR</th>\n",
       "      <th>Snore</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>Therm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>[131.0, 373.43917690138403, 320.18505119204775...</td>\n",
       "      <td>[363.0, 27.645378352257325, 112.49019751638068...</td>\n",
       "      <td>[399.0, 160.85451594413797, 24.886679640510295...</td>\n",
       "      <td>[56.0, 326.52585125323947, 475.55658303715313,...</td>\n",
       "      <td>[410.0, 525.3694447990622, 266.4647322047152, ...</td>\n",
       "      <td>[357.0, 69.35163643456059, 93.02755235868437, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>[173.0, 208.3229580285688, 347.1726460972568, ...</td>\n",
       "      <td>[12.999999999999972, 395.3931049168309, 393.29...</td>\n",
       "      <td>[170.0, 451.56759613646807, 511.37713536926873...</td>\n",
       "      <td>[468.0, 285.79856881871865, 453.84142507015247...</td>\n",
       "      <td>[94.0, 504.3691752261143, 212.3485059663618, 6...</td>\n",
       "      <td>[239.0, 0.8394265068872642, 161.28955000941278...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Airflow  \\\n",
       "958  [131.0, 373.43917690138403, 320.18505119204775...   \n",
       "959  [173.0, 208.3229580285688, 347.1726460972568, ...   \n",
       "\n",
       "                                                   ECG  \\\n",
       "958  [363.0, 27.645378352257325, 112.49019751638068...   \n",
       "959  [12.999999999999972, 395.3931049168309, 393.29...   \n",
       "\n",
       "                                                    HR  \\\n",
       "958  [399.0, 160.85451594413797, 24.886679640510295...   \n",
       "959  [170.0, 451.56759613646807, 511.37713536926873...   \n",
       "\n",
       "                                                 Snore  \\\n",
       "958  [56.0, 326.52585125323947, 475.55658303715313,...   \n",
       "959  [468.0, 285.79856881871865, 453.84142507015247...   \n",
       "\n",
       "                                                  SpO2  \\\n",
       "958  [410.0, 525.3694447990622, 266.4647322047152, ...   \n",
       "959  [94.0, 504.3691752261143, 212.3485059663618, 6...   \n",
       "\n",
       "                                                 Therm  \n",
       "958  [357.0, 69.35163643456059, 93.02755235868437, ...  \n",
       "959  [239.0, 0.8394265068872642, 161.28955000941278...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp1.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the cells from numpy arrays back into pd Series\n",
    "df_series = df_temp1.applymap(lambda x: pd.Series(x.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airflow</th>\n",
       "      <th>ECG</th>\n",
       "      <th>HR</th>\n",
       "      <th>Snore</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>Therm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0       131.000000\n",
       "1       373.439177\n",
       "2       ...</td>\n",
       "      <td>0       363.000000\n",
       "1        27.645378\n",
       "2       ...</td>\n",
       "      <td>0       399.000000\n",
       "1       160.854516\n",
       "2       ...</td>\n",
       "      <td>0        56.000000\n",
       "1       326.525851\n",
       "2       ...</td>\n",
       "      <td>0       410.000000\n",
       "1       525.369445\n",
       "2       ...</td>\n",
       "      <td>0       357.000000\n",
       "1        69.351636\n",
       "2       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>0       173.000000\n",
       "1       208.322958\n",
       "2       ...</td>\n",
       "      <td>0        13.000000\n",
       "1       395.393105\n",
       "2       ...</td>\n",
       "      <td>0       170.000000\n",
       "1       451.567596\n",
       "2       ...</td>\n",
       "      <td>0       468.000000\n",
       "1       285.798569\n",
       "2       ...</td>\n",
       "      <td>0        94.000000\n",
       "1       504.369175\n",
       "2       ...</td>\n",
       "      <td>0       239.000000\n",
       "1         0.839427\n",
       "2       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Airflow  \\\n",
       "958  0       131.000000\n",
       "1       373.439177\n",
       "2       ...   \n",
       "959  0       173.000000\n",
       "1       208.322958\n",
       "2       ...   \n",
       "\n",
       "                                                   ECG  \\\n",
       "958  0       363.000000\n",
       "1        27.645378\n",
       "2       ...   \n",
       "959  0        13.000000\n",
       "1       395.393105\n",
       "2       ...   \n",
       "\n",
       "                                                    HR  \\\n",
       "958  0       399.000000\n",
       "1       160.854516\n",
       "2       ...   \n",
       "959  0       170.000000\n",
       "1       451.567596\n",
       "2       ...   \n",
       "\n",
       "                                                 Snore  \\\n",
       "958  0        56.000000\n",
       "1       326.525851\n",
       "2       ...   \n",
       "959  0       468.000000\n",
       "1       285.798569\n",
       "2       ...   \n",
       "\n",
       "                                                  SpO2  \\\n",
       "958  0       410.000000\n",
       "1       525.369445\n",
       "2       ...   \n",
       "959  0        94.000000\n",
       "1       504.369175\n",
       "2       ...   \n",
       "\n",
       "                                                 Therm  \n",
       "958  0       357.000000\n",
       "1        69.351636\n",
       "2       ...  \n",
       "959  0       239.000000\n",
       "1         0.839427\n",
       "2       ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_series.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use minirocket to transform df_series into an input for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airflow</th>\n",
       "      <th>ECG</th>\n",
       "      <th>Snore</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>Therm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0       106.000000\n",
       "1       250.713451\n",
       "2       ...</td>\n",
       "      <td>0       241.000000\n",
       "1       400.365784\n",
       "2       ...</td>\n",
       "      <td>0       353.000000\n",
       "1       395.194174\n",
       "2       ...</td>\n",
       "      <td>0       299.000000\n",
       "1       193.067202\n",
       "2       ...</td>\n",
       "      <td>0       224.000000\n",
       "1        39.828052\n",
       "2       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0       369.000000\n",
       "1        65.726544\n",
       "2       ...</td>\n",
       "      <td>0       436.000000\n",
       "1       151.886849\n",
       "2       ...</td>\n",
       "      <td>0       425.000000\n",
       "1       172.074492\n",
       "2       ...</td>\n",
       "      <td>0       422.000000\n",
       "1       139.518724\n",
       "2       ...</td>\n",
       "      <td>0       349.000000\n",
       "1       413.041706\n",
       "2       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Airflow  \\\n",
       "0  0       106.000000\n",
       "1       250.713451\n",
       "2       ...   \n",
       "1  0       369.000000\n",
       "1        65.726544\n",
       "2       ...   \n",
       "\n",
       "                                                 ECG  \\\n",
       "0  0       241.000000\n",
       "1       400.365784\n",
       "2       ...   \n",
       "1  0       436.000000\n",
       "1       151.886849\n",
       "2       ...   \n",
       "\n",
       "                                               Snore  \\\n",
       "0  0       353.000000\n",
       "1       395.194174\n",
       "2       ...   \n",
       "1  0       425.000000\n",
       "1       172.074492\n",
       "2       ...   \n",
       "\n",
       "                                                SpO2  \\\n",
       "0  0       299.000000\n",
       "1       193.067202\n",
       "2       ...   \n",
       "1  0       422.000000\n",
       "1       139.518724\n",
       "2       ...   \n",
       "\n",
       "                                               Therm  \n",
       "0  0       224.000000\n",
       "1        39.828052\n",
       "2       ...  \n",
       "1  0       349.000000\n",
       "1       413.041706\n",
       "2       ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the minirocket in our local file system\n",
    "# remove HR from the dataframe since it was not included in our training\n",
    "df_series.drop(\"HR\", axis=1, inplace=True)\n",
    "df_series.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Flow1', 'EKG', 'Snore', 'SpO2', 'Flow2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Change the names of the columns to match the names in the minirocket model\n",
    "df_series.rename(\n",
    "    columns={\n",
    "        \"Airflow\": \"Flow1\",\n",
    "        \"ECG\": \"EKG\",\n",
    "        \"Snore\": \"Snore\",\n",
    "        \"SpO2\": \"SpO2\",\n",
    "        \"Therm\": \"Flow2\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Verify the new column names\n",
    "print(df_series.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EKG', 'Snore', 'Flow1', 'Flow2', 'SpO2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# change the order of the columns to match the order in the minirocket model\n",
    "\n",
    "desired_order = [\"EKG\", \"Snore\", \"Flow1\", \"Flow2\", \"SpO2\"]\n",
    "df_series = df_series.reindex(columns=desired_order)\n",
    "\n",
    "# Verify the new column order\n",
    "print(df_series.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    r\"C:\\Users\\Toshiba\\Documents\\PD2_john\\modelsAndTransformers\\MiniRV2_FitOnTrainingSetOnly_1020.pickle\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    miniR = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_readings = df_series.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_readings_transformed = miniR.transform(sensor_readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 49980)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_readings_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model Pipeline and use it to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\n",
    "    r\"C:\\Users\\Toshiba\\Documents\\PD2_john\\modelsAndTransformers\\MiniR_pipeline2_1020_SVC_Recall_76_76_avg_75.joblib\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try to predict and use the model first with our own data that we know comes from real sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EKG__0    EKG__1    EKG__2    EKG__3    EKG__4    EKG__5    EKG__6  \\\n",
      "0  0.100980  0.948039  0.000000  0.634314  1.000000  0.045098  0.857843   \n",
      "1  0.363725  0.659804  0.212745  0.487255  0.704902  0.273529  0.622549   \n",
      "\n",
      "     EKG__7    EKG__8    EKG__9  ...  SpO2__9987  SpO2__9988  SpO2__9989  \\\n",
      "0  0.000000  0.166667  0.984314  ...         0.0         0.0         1.0   \n",
      "1  0.187255  0.408824  0.667647  ...         0.0         0.0         1.0   \n",
      "\n",
      "   SpO2__9990  SpO2__9991  SpO2__9992  SpO2__9993  SpO2__9994  SpO2__9995  \\\n",
      "0    0.169608    0.626471    1.000000         0.0         1.0         0.0   \n",
      "1    0.228431    0.583333    0.935294         0.0         1.0         0.0   \n",
      "\n",
      "   Events  \n",
      "0       0  \n",
      "1       0  \n",
      "\n",
      "[2 rows x 49981 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path or URL of the CSV file\n",
    "file_path = (\n",
    "    r\"C:\\Users\\Toshiba\\Documents\\PD2_john\\modelsAndTransformers\\XTestMiniRWithYtest.csv\"\n",
    ")\n",
    "\n",
    "# Read the CSV file into a dataframe\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Now you can work with the dataframe 'df'\n",
    "# For example, you can display the first few rows using the head() method\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 49980)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EKG__0    EKG__1    EKG__2    EKG__3    EKG__4    EKG__5    EKG__6  \\\n",
      "0  0.100980  0.948039  0.000000  0.634314  1.000000  0.045098  0.857843   \n",
      "1  0.363725  0.659804  0.212745  0.487255  0.704902  0.273529  0.622549   \n",
      "2  0.335294  0.814706  0.006863  0.648039  0.976471  0.189216  0.737255   \n",
      "3  0.439216  0.715686  0.251961  0.575490  0.787255  0.360784  0.625490   \n",
      "4  0.334314  0.710784  0.134314  0.503922  0.877451  0.274510  0.600980   \n",
      "\n",
      "     EKG__7    EKG__8    EKG__9  ...  SpO2__9986  SpO2__9987  SpO2__9988  \\\n",
      "0  0.000000  0.166667  0.984314  ...    0.736275         0.0         0.0   \n",
      "1  0.187255  0.408824  0.667647  ...    0.670588         0.0         0.0   \n",
      "2  0.004902  0.373529  0.925490  ...    0.626471         0.0         0.0   \n",
      "3  0.163725  0.498039  0.746078  ...    0.635294         0.0         0.0   \n",
      "4  0.049020  0.383333  0.767647  ...    0.750980         0.0         0.0   \n",
      "\n",
      "   SpO2__9989  SpO2__9990  SpO2__9991  SpO2__9992  SpO2__9993  SpO2__9994  \\\n",
      "0         1.0    0.169608    0.626471    1.000000         0.0         1.0   \n",
      "1         1.0    0.228431    0.583333    0.935294         0.0         1.0   \n",
      "2         1.0    0.249020    0.603922    0.905882         0.0         1.0   \n",
      "3         1.0    0.241176    0.626471    1.000000         0.0         1.0   \n",
      "4         1.0    0.124510    0.626471    1.000000         0.0         1.0   \n",
      "\n",
      "   SpO2__9995  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n",
      "\n",
      "[5 rows x 49980 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is called 'df' and you want to drop the column 'ColumnName'\n",
    "df = df.drop(\"Events\", axis=1)\n",
    "\n",
    "# Verify the updated dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: scaler\n",
      "Type: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "Classifier Parameters:\n",
      "{'copy': True, 'with_mean': True, 'with_std': True}\n",
      "StandardScaler Parameters:\n",
      "{'copy': True, 'with_mean': True, 'with_std': True}\n",
      "-----------------------\n",
      "Step: svc\n",
      "Type: <class 'sklearn.svm._classes.SVC'>\n",
      "Classifier Parameters:\n",
      "{'C': 100, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# check what the model looks like\n",
    "for step_name, step in model.steps:\n",
    "    print(\"Step:\", step_name)\n",
    "    print(\"Type:\", type(step))\n",
    "\n",
    "    # Check if the step is a classifier\n",
    "    if hasattr(step, \"get_params\"):\n",
    "        print(\"Classifier Parameters:\")\n",
    "        print(step.get_params())\n",
    "\n",
    "    # Check if the step is a StandardScaler\n",
    "    if isinstance(step, StandardScaler):\n",
    "        print(\"StandardScaler Parameters:\")\n",
    "        print(step.get_params())\n",
    "\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = model.predict(sensor_readings_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Severity': 'Normal', 'AHI': 0.0, 'TimeIn': '2023-06-12 08:00:00', 'TimeOut': '2023-06-12 16:00:00', 'UserID': 'OYKKRb', 'Normal': 1920, 'Apnea': 0, 'Hypopnea': 0}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def create_integer_counts_dict(arr, AHI_table):\n",
    "    for num in arr:\n",
    "        if num == 0:\n",
    "            AHI_table[\"Normal\"] += 1\n",
    "        elif num == 1:\n",
    "            AHI_table[\"Apnea\"] += 1\n",
    "        elif num == 2:\n",
    "            AHI_table[\"Hypopnea\"] += 1\n",
    "    from datetime import datetime\n",
    "\n",
    "    # Convert the datetime strings into datetime objects\n",
    "    datetime_str1 = AHI_table[\"TimeIn\"]\n",
    "    datetime_str2 = AHI_table[\"TimeOut\"]\n",
    "    datetime_format = \"%Y-%m-%d %H:%M:%S\"  # Format of the datetime strings\n",
    "\n",
    "    datetime_obj1 = datetime.strptime(datetime_str1, datetime_format)\n",
    "    datetime_obj2 = datetime.strptime(datetime_str2, datetime_format)\n",
    "\n",
    "    # Calculate the time difference in hours\n",
    "    time_difference = (datetime_obj2 - datetime_obj1).total_seconds() / 3600\n",
    "\n",
    "    # Calculate the AHI\n",
    "    AHI = (AHI_table[\"Apnea\"] + AHI_table[\"Hypopnea\"]) / time_difference\n",
    "\n",
    "    # Add the AHI to the dictionary\n",
    "    AHI_table[\"AHI\"] = AHI\n",
    "\n",
    "    # Add the severity to the dictionary\n",
    "\n",
    "    if AHI < 5:\n",
    "        AHI_table[\"Severity\"] = \"Normal\"\n",
    "    elif AHI >= 5 and AHI < 15:\n",
    "        AHI_table[\"Severity\"] = \"Mild\"\n",
    "    elif AHI >= 15 and AHI < 30:\n",
    "        AHI_table[\"Severity\"] = \"Moderate\"\n",
    "    elif AHI >= 30:\n",
    "        AHI_table[\"Severity\"] = \"Severe\"\n",
    "\n",
    "    return AHI_table\n",
    "\n",
    "\n",
    "AHI_table = create_integer_counts_dict(df_predict, AHI_table)\n",
    "\n",
    "# Print the dictionary\n",
    "print(AHI_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
